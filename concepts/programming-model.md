## 数据流编程模型

### Levels of Abstraction

Flink提供了开发流/批处理应用程序的不同抽象级别。

![levels_of_abstraction](../images/levels_of_abstraction.svg)

- 最低级别抽象只提供有状态流。它通过Process函数嵌入到DataStream API中。它允许用户自由处理来自一个或多个流的事件，并使用一致的容错状态。此外，用户可以注册事件时间和处理时间回调，允许程序实现复杂的计算。

- 实际上，大多数应用程序不需要上面描述的低层抽象，而是根据核心API (DataStream API(有界/无界流)和DataSet API(有界数据集)进行编程。这些连贯api为数据处理提供了常见的构建块，比如用户指定的各种形式的转换、连接、聚合、窗口、状态等。在这些api中处理的数据类型用各自的编程语言表示为类。

低层流程函数与DataStream API集成，使得仅对某些操作进行低层抽象成为可能。DataSet API在有界数据集上提供了额外的原语，比如循环/迭代。

- 表API是一个以表为中心的声明性DSL，表可以(在表示流时)动态地更改表。表API遵循(扩展的)关系模型:表有一个附加的模式(类似于关系数据库中的表)，而API提供了类似的操作，如select、project、join、group-by、aggregate等。表API程序声明性地定义应该执行什么逻辑操作，而不是确切地指定操作代码的外观。虽然表API可以通过各种类型的用户定义函数进行扩展，但是它比核心API更缺乏表现力，但是使用起来更简洁(编写的代码更少)。此外，表API程序还需要经过一个在执行之前应用优化规则的优化器。

可以在表和DataStream/DataSet之间无缝转换，允许程序混合表API和DataStream和DataSet API。

- Flink提供的最高级抽象是SQL。这种抽象在语义和表达性上都类似于表API，但将程序表示为SQL查询表达式。SQL抽象与表API紧密交互，SQL查询可以在表API中定义的表上执行。

### Programs and Dataflows
Flink程序的基本构建块是流和转换。(注意，在Flink的DataSet API中使用的数据集也是内部流的——稍后会详细介绍)。从概念上讲，流是数据记录的流(可能永远不会结束)，转换是一个操作，它接受一个或多个流作为输入，并生成一个或多个输出流。

当执行时，Flink程序被映射到流数据流，由流和转换操作符组成。每个数据流开始于一个或多个源，结束于一个或多个接收器。数据流类似于任意有向无环图(DAGs)。虽然通过迭代构造允许使用特殊形式的循环，但是为了简单起见，我们将在大多数情况下忽略这一点。

![program_dataflow](../images/program_dataflow.svg)

通常，程序中的转换与数据流中的操作符之间存在一对一的对应关系。然而，有时一个转换可能包含多个转换操作符。

源和接收器记录在流连接器和批连接器文档中。转换记录在DataStream操作符和数据集转换中。

---
### Parallel Dataflows
Flink中的程序本质上是并行和分布式的。在执行期间，一个流有一个或多个流分区，每个操作符有一个或多个操作符子任务。操作符子任务彼此独立，并在不同的线程中执行，也可能在不同的机器或容器上执行。

运算符子任务的数量是该特定运算符的并行度。流的并行性总是它的产生算子的并行性。同一程序的不同操作符可能具有不同级别的并行性。

![parallel_dataflow](../images/parallel_dataflow.svg)

Streams可以在两个操作符之间以一对一(或转发)模式传输数据，也可以采用重新分发模式:

- **`One-to-one`**流(例如上图中的源和map()操作符)保持元素的分区和顺序。这意味着map()操作符的子任务[1]将看到与源操作符的子任务[1]生成的元素顺序相同的元素。

- **`Redistributing`**流(如上面的map()和keyBy/window之间，以及keyBy/window和Sink之间)会改变流的分区。每个操作符子任务根据所选的转换向不同的目标子任务发送数据。例如keyBy()(通过散列键重新分区)、broadcast()或()(随机重新分区)。在重分发交换中，元素之间的顺序只保留在每对发送和接收子任务中(例如map()的子任务[1]和keyBy/window的子任务[2])。因此，在本例中，保留了每个键中的顺序，但是并行性确实引入了关于不同键的聚合结果到达接收器的顺序的非确定性。

有关配置和控制并行性的详细信息可以在有关并行执行的文档中找到。

---
### Windows
聚合事件(例如计数、和)在流上的工作方式与在批处理中不同。例如，不可能计算流中的所有元素，因为流通常是无限的(无界的)。相反，流上的聚合(计数、和等)由窗口限定范围，例如“过去5分钟内的计数”或“最后100个元素的总和”。

Windows可以是时间驱动的(例如:每30秒)，也可以是数据驱动的(例如:每100个元素)。一个典型的例子是区分不同类型的窗口，比如翻滚窗口(没有重叠)、滑动窗口(有重叠)和会话窗口(中间有一个不活动的间隙)。

![windows](../images/windows.svg)

更多的窗口例子可以在这篇博文中找到。更多细节在窗口文档中。

---
### Time
当提到流媒体程序中的时间(例如定义windows)时，可以指不同的时间概念:

- **`Event Time`**是创建事件的时间。它通常由事件中的时间戳描述，例如由生产传感器或生产服务附加的时间戳。Flink通过时间戳分配程序访问事件时间戳。

- **`Ingestion time`**是事件在源操作符处进入Flink数据流的时间。

- **`Processing Time`**是每个执行基于时间的操作的操作符的本地时间。

![event_ingestion_processing_time](../images/event_ingestion_processing_time.svg)

关于如何处理时间的更多细节在事件时间文档中。

### Stateful Operations
虽然数据流中的许多操作一次只查看一个单独的事件(例如事件解析器)，但是有些操作可以跨多个事件(例如窗口操作符)记住信息。这些操作称为有状态的。

有状态操作的状态维护在可视为嵌入式键/值存储的地方。状态与有状态操作符读取的流一起严格地分区和分布。因此，只有在keyBy()函数之后的键控流上才能访问键/值状态，并且只能访问与当前事件的键关联的值。将流的键与状态对齐可以确保所有状态更新都是本地操作，从而确保一致性，而不需要事务开销。这种对齐还允许Flink重新分配状态并透明地调整流分区。

![state_partitioning](../images/state_partitioning.svg)

有关更多信息，请参阅有关[状态]()的文档。

### Checkpoints for Fault Tolerance

Flink使用流回放和检查点的组合实现容错。检查点与每个输入流中的特定点以及每个操作符的对应状态相关。流数据流可以从检查点恢复，同时通过恢复操作符的状态并从检查点重播事件来保持一致性(精确地说，一次处理语义)。

检查点间隔是一种用恢复时间(需要重放的事件数量)来抵消执行期间容错开销的方法。

容错内部的描述提供了关于Flink如何管理检查点和相关主题的更多信息。启用和配置检查点的详细信息在检查点API文档中。

### Batch on Streaming
Flink作为流程序的一种特殊情况执行批处理程序，其中流是有界的(有限数量的元素)。数据集在内部被视为数据流。因此，上述概念同样适用于批处理程序，也适用于流媒体程序，只有少数例外:

- 批处理程序的容错不使用检查点。恢复是通过完全重放流来实现的。这是可能的，因为输入是有界的。这使得恢复的成本更高，但是使常规处理更便宜，因为它避免了检查点。

- DataSet API中的有状态操作使用简化的内存/内核外数据结构，而不是键/值索引。

- DataSet API引入了特殊的同步(基于超步)迭代，这只可能在有界流上实现。有关详细信息，请查看iteration文档。


下一个步骤
继续Flink的[`Distributed Runtime]()中的基本概念。

